// AETHER LEXER - Pure Aether Implementation
// Tokenizes Aether source code into tokens
// Part of the world-class Aether compiler

// No imports needed - uses __builtin_* intrinsics directly

// ============================================================================
// TOKEN TYPES
// ============================================================================

const TOK_EOF: Int = 0
const TOK_INT: Int = 1
const TOK_FLOAT: Int = 2
const TOK_ID: Int = 3
const TOK_STR: Int = 4
const TOK_CHAR: Int = 5

// Delimiters
const TOK_LPAREN: Int = 10
const TOK_RPAREN: Int = 11
const TOK_LBRACE: Int = 12
const TOK_RBRACE: Int = 13
const TOK_LBRACK: Int = 14
const TOK_RBRACK: Int = 15
const TOK_COMMA: Int = 16
const TOK_COLON: Int = 17
const TOK_SEMI: Int = 18
const TOK_DOT: Int = 19

// Operators
const TOK_ARROW: Int = 20
const TOK_DARROW: Int = 21
const TOK_EQ: Int = 22
const TOK_EQEQ: Int = 23
const TOK_NE: Int = 24
const TOK_LT: Int = 25
const TOK_LE: Int = 26
const TOK_GT: Int = 27
const TOK_GE: Int = 28
const TOK_PLUS: Int = 30
const TOK_MINUS: Int = 31
const TOK_STAR: Int = 32
const TOK_SLASH: Int = 33
const TOK_PERCENT: Int = 34
const TOK_AMP: Int = 35
const TOK_PIPE: Int = 36
const TOK_BANG: Int = 37
const TOK_CARET: Int = 38
const TOK_TILDE: Int = 39
const TOK_AMPAMP: Int = 40
const TOK_PIPEPIPE: Int = 41
const TOK_PLUSEQ: Int = 42
const TOK_MINUSEQ: Int = 43
const TOK_STAREQ: Int = 44
const TOK_SLASHEQ: Int = 45
const TOK_DOTDOT: Int = 46
const TOK_DOTDOTDOT: Int = 47
const TOK_QUESTION: Int = 48
const TOK_AT: Int = 49

// Keywords
const TOK_FUNC: Int = 50
const TOK_LET: Int = 51
const TOK_MUT: Int = 52
const TOK_IF: Int = 53
const TOK_ELSE: Int = 54
const TOK_WHILE: Int = 55
const TOK_FOR: Int = 56
const TOK_RETURN: Int = 57
const TOK_STRUCT: Int = 58
const TOK_ENUM: Int = 59
const TOK_TRAIT: Int = 60
const TOK_IMPORT: Int = 61
const TOK_CONST: Int = 62
const TOK_PUB: Int = 63
const TOK_MATCH: Int = 64
const TOK_TRUE: Int = 65
const TOK_FALSE: Int = 66
const TOK_BREAK: Int = 67
const TOK_CONTINUE: Int = 68
const TOK_TYPE: Int = 69
const TOK_IMPL: Int = 70
const TOK_SELF: Int = 71
const TOK_AS: Int = 72
const TOK_IN: Int = 73
const TOK_WHERE: Int = 74
const TOK_ASYNC: Int = 75
const TOK_AWAIT: Int = 76
const TOK_SPAWN: Int = 77
const TOK_EFFECT: Int = 78
const TOK_HANDLE: Int = 79
const TOK_RESUME: Int = 80

// ============================================================================
// TOKEN STRUCTURE: [type, value, line, col, len, str_ptr]
// ============================================================================

func token_new(typ: Int, val: Int, line: Int, col: Int, len: Int) -> Int {
    let t = __builtin_malloc(48)
    __builtin_store64(t, typ)
    __builtin_store64(t + 8, val)
    __builtin_store64(t + 16, line)
    __builtin_store64(t + 24, col)
    __builtin_store64(t + 32, len)
    __builtin_store64(t + 40, 0)
    t
}

func token_type(t: Int) -> Int { __builtin_load64(t) }
func token_value(t: Int) -> Int { __builtin_load64(t + 8) }
func token_line(t: Int) -> Int { __builtin_load64(t + 16) }
func token_col(t: Int) -> Int { __builtin_load64(t + 24) }
func token_len(t: Int) -> Int { __builtin_load64(t + 32) }
func token_str(t: Int) -> Int { __builtin_load64(t + 40) }
func token_set_str(t: Int, s: Int) { __builtin_store64(t + 40, s) }

// ============================================================================
// LEXER STATE: [src, len, pos, line, col]
// ============================================================================

func lexer_new(src: Int, len: Int) -> Int {
    let l = __builtin_malloc(40)
    __builtin_store64(l, src)
    __builtin_store64(l + 8, len)
    __builtin_store64(l + 16, 0)   // pos
    __builtin_store64(l + 24, 1)   // line
    __builtin_store64(l + 32, 1)   // col
    l
}

func lexer_src(l: Int) -> Int { __builtin_load64(l) }
func lexer_len(l: Int) -> Int { __builtin_load64(l + 8) }
func lexer_pos(l: Int) -> Int { __builtin_load64(l + 16) }
func lexer_line(l: Int) -> Int { __builtin_load64(l + 24) }
func lexer_col(l: Int) -> Int { __builtin_load64(l + 32) }

func lexer_set_pos(l: Int, p: Int) { __builtin_store64(l + 16, p) }
func lexer_set_line(l: Int, n: Int) { __builtin_store64(l + 24, n) }
func lexer_set_col(l: Int, c: Int) { __builtin_store64(l + 32, c) }

func lexer_peek(l: Int) -> Int {
    if lexer_pos(l) >= lexer_len(l) { return 0 }
    __builtin_load8(lexer_src(l) + lexer_pos(l))
}

func lexer_peek_n(l: Int, n: Int) -> Int {
    let pos = lexer_pos(l) + n
    if pos >= lexer_len(l) { return 0 }
    __builtin_load8(lexer_src(l) + pos)
}

func lexer_advance(l: Int) {
    let c = lexer_peek(l)
    lexer_set_pos(l, lexer_pos(l) + 1)
    if c == 10 {
        lexer_set_line(l, lexer_line(l) + 1)
        lexer_set_col(l, 1)
    } else {
        lexer_set_col(l, lexer_col(l) + 1)
    }
}

func lexer_skip_whitespace(l: Int) {
    print(87) print(48) print(10)  // W0 - entering
    while 1 == 1 {
        print(87) print(49) print(10)  // W1 - in loop
        let c = lexer_peek(l)
        print(87) print(50) print(10)  // W2 - after peek
        if c == 32 || c == 9 || c == 10 || c == 13 {
            lexer_advance(l)
        } else if c == 47 && lexer_peek_n(l, 1) == 47 {
            // Line comment
            while lexer_peek(l) != 10 && lexer_peek(l) != 0 {
                lexer_advance(l)
            }
        } else if c == 47 && lexer_peek_n(l, 1) == 42 {
            // Block comment
            lexer_advance(l)
            lexer_advance(l)
            while 1 == 1 {
                if lexer_peek(l) == 0 { break }
                if lexer_peek(l) == 42 && lexer_peek_n(l, 1) == 47 {
                    lexer_advance(l)
                    lexer_advance(l)
                    break
                }
                lexer_advance(l)
            }
        } else {
            print(87) print(51) print(10)  // W3 - returning
            return
        }
    }
}

func is_alpha(c: Int) -> Int {
    if c >= 65 && c <= 90 { return 1 }
    if c >= 97 && c <= 122 { return 1 }
    if c == 95 { return 1 }
    0
}

func is_digit(c: Int) -> Int {
    if c >= 48 && c <= 57 { return 1 }
    0
}

func is_alnum(c: Int) -> Int {
    if is_alpha(c) == 1 { return 1 }
    if is_digit(c) == 1 { return 1 }
    0
}

func str_eq_n(a: Int, b: Int, len: Int) -> Int {
    let i = 0
    while i < len {
        if __builtin_load8(a + i) != __builtin_load8(b + i) { return 0 }
        i = i + 1
    }
    1
}

// Keyword lookup
func keyword_lookup(buf: Int, len: Int) -> Int {
    // Check common keywords by length for efficiency
    if len == 2 {
        if __builtin_load8(buf) == 105 && __builtin_load8(buf + 1) == 102 { return TOK_IF }
        if __builtin_load8(buf) == 105 && __builtin_load8(buf + 1) == 110 { return TOK_IN }
        if __builtin_load8(buf) == 97 && __builtin_load8(buf + 1) == 115 { return TOK_AS }
    }
    if len == 3 {
        if __builtin_load8(buf) == 108 && __builtin_load8(buf + 1) == 101 && __builtin_load8(buf + 2) == 116 { return TOK_LET }
        if __builtin_load8(buf) == 109 && __builtin_load8(buf + 1) == 117 && __builtin_load8(buf + 2) == 116 { return TOK_MUT }
        if __builtin_load8(buf) == 102 && __builtin_load8(buf + 1) == 111 && __builtin_load8(buf + 2) == 114 { return TOK_FOR }
        if __builtin_load8(buf) == 112 && __builtin_load8(buf + 1) == 117 && __builtin_load8(buf + 2) == 98 { return TOK_PUB }
    }
    if len == 4 {
        if __builtin_load8(buf) == 102 && __builtin_load8(buf + 1) == 117 && __builtin_load8(buf + 2) == 110 && __builtin_load8(buf + 3) == 99 { return TOK_FUNC }
        if __builtin_load8(buf) == 101 && __builtin_load8(buf + 1) == 108 && __builtin_load8(buf + 2) == 115 && __builtin_load8(buf + 3) == 101 { return TOK_ELSE }
        if __builtin_load8(buf) == 116 && __builtin_load8(buf + 1) == 114 && __builtin_load8(buf + 2) == 117 && __builtin_load8(buf + 3) == 101 { return TOK_TRUE }
        if __builtin_load8(buf) == 116 && __builtin_load8(buf + 1) == 121 && __builtin_load8(buf + 2) == 112 && __builtin_load8(buf + 3) == 101 { return TOK_TYPE }
        if __builtin_load8(buf) == 105 && __builtin_load8(buf + 1) == 109 && __builtin_load8(buf + 2) == 112 && __builtin_load8(buf + 3) == 108 { return TOK_IMPL }
        if __builtin_load8(buf) == 115 && __builtin_load8(buf + 1) == 101 && __builtin_load8(buf + 2) == 108 && __builtin_load8(buf + 3) == 102 { return TOK_SELF }
        if __builtin_load8(buf) == 101 && __builtin_load8(buf + 1) == 110 && __builtin_load8(buf + 2) == 117 && __builtin_load8(buf + 3) == 109 { return TOK_ENUM }
    }
    if len == 5 {
        if __builtin_load8(buf) == 119 && __builtin_load8(buf + 1) == 104 && __builtin_load8(buf + 2) == 105 && __builtin_load8(buf + 3) == 108 && __builtin_load8(buf + 4) == 101 { return TOK_WHILE }
        if __builtin_load8(buf) == 98 && __builtin_load8(buf + 1) == 114 && __builtin_load8(buf + 2) == 101 && __builtin_load8(buf + 3) == 97 && __builtin_load8(buf + 4) == 107 { return TOK_BREAK }
        if __builtin_load8(buf) == 99 && __builtin_load8(buf + 1) == 111 && __builtin_load8(buf + 2) == 110 && __builtin_load8(buf + 3) == 115 && __builtin_load8(buf + 4) == 116 { return TOK_CONST }
        if __builtin_load8(buf) == 109 && __builtin_load8(buf + 1) == 97 && __builtin_load8(buf + 2) == 116 && __builtin_load8(buf + 3) == 99 && __builtin_load8(buf + 4) == 104 { return TOK_MATCH }
        if __builtin_load8(buf) == 116 && __builtin_load8(buf + 1) == 114 && __builtin_load8(buf + 2) == 97 && __builtin_load8(buf + 3) == 105 && __builtin_load8(buf + 4) == 116 { return TOK_TRAIT }
        if __builtin_load8(buf) == 102 && __builtin_load8(buf + 1) == 97 && __builtin_load8(buf + 2) == 108 && __builtin_load8(buf + 3) == 115 && __builtin_load8(buf + 4) == 101 { return TOK_FALSE }
        if __builtin_load8(buf) == 97 && __builtin_load8(buf + 1) == 115 && __builtin_load8(buf + 2) == 121 && __builtin_load8(buf + 3) == 110 && __builtin_load8(buf + 4) == 99 { return TOK_ASYNC }
        if __builtin_load8(buf) == 97 && __builtin_load8(buf + 1) == 119 && __builtin_load8(buf + 2) == 97 && __builtin_load8(buf + 3) == 105 && __builtin_load8(buf + 4) == 116 { return TOK_AWAIT }
        if __builtin_load8(buf) == 115 && __builtin_load8(buf + 1) == 112 && __builtin_load8(buf + 2) == 97 && __builtin_load8(buf + 3) == 119 && __builtin_load8(buf + 4) == 110 { return TOK_SPAWN }
        if __builtin_load8(buf) == 119 && __builtin_load8(buf + 1) == 104 && __builtin_load8(buf + 2) == 101 && __builtin_load8(buf + 3) == 114 && __builtin_load8(buf + 4) == 101 { return TOK_WHERE }
    }
    if len == 6 {
        if __builtin_load8(buf) == 114 && __builtin_load8(buf + 1) == 101 && __builtin_load8(buf + 2) == 116 && __builtin_load8(buf + 3) == 117 && __builtin_load8(buf + 4) == 114 && __builtin_load8(buf + 5) == 110 { return TOK_RETURN }
        if __builtin_load8(buf) == 115 && __builtin_load8(buf + 1) == 116 && __builtin_load8(buf + 2) == 114 && __builtin_load8(buf + 3) == 117 && __builtin_load8(buf + 4) == 99 && __builtin_load8(buf + 5) == 116 { return TOK_STRUCT }
        if __builtin_load8(buf) == 105 && __builtin_load8(buf + 1) == 109 && __builtin_load8(buf + 2) == 112 && __builtin_load8(buf + 3) == 111 && __builtin_load8(buf + 4) == 114 && __builtin_load8(buf + 5) == 116 { return TOK_IMPORT }
        if __builtin_load8(buf) == 101 && __builtin_load8(buf + 1) == 102 && __builtin_load8(buf + 2) == 102 && __builtin_load8(buf + 3) == 101 && __builtin_load8(buf + 4) == 99 && __builtin_load8(buf + 5) == 116 { return TOK_EFFECT }
        if __builtin_load8(buf) == 104 && __builtin_load8(buf + 1) == 97 && __builtin_load8(buf + 2) == 110 && __builtin_load8(buf + 3) == 100 && __builtin_load8(buf + 4) == 108 && __builtin_load8(buf + 5) == 101 { return TOK_HANDLE }
        if __builtin_load8(buf) == 114 && __builtin_load8(buf + 1) == 101 && __builtin_load8(buf + 2) == 115 && __builtin_load8(buf + 3) == 117 && __builtin_load8(buf + 4) == 109 && __builtin_load8(buf + 5) == 101 { return TOK_RESUME }
    }
    if len == 8 {
        if __builtin_load8(buf) == 99 && __builtin_load8(buf + 1) == 111 && __builtin_load8(buf + 2) == 110 && __builtin_load8(buf + 3) == 116 && __builtin_load8(buf + 4) == 105 && __builtin_load8(buf + 5) == 110 && __builtin_load8(buf + 6) == 117 && __builtin_load8(buf + 7) == 101 { return TOK_CONTINUE }
    }
    TOK_ID
}

// ============================================================================
// MAIN LEXER FUNCTION
// ============================================================================

func lexer_next(l: Int) -> Int {
    lexer_skip_whitespace(l)
    let line = lexer_line(l)
    let col = lexer_col(l)
    let c = lexer_peek(l)
    
    if c == 0 { return token_new(TOK_EOF, 0, line, col, 0) }
    
    // Numbers
    if is_digit(c) == 1 {
        let num = 0
        let is_float = 0
        while is_digit(lexer_peek(l)) == 1 {
            num = num * 10 + lexer_peek(l) - 48
            lexer_advance(l)
        }
        if lexer_peek(l) == 46 && is_digit(lexer_peek_n(l, 1)) == 1 {
            is_float = 1
            lexer_advance(l)
            let frac = 0
            let div = 1
            while is_digit(lexer_peek(l)) == 1 {
                frac = frac * 10 + lexer_peek(l) - 48
                div = div * 10
                lexer_advance(l)
            }
        }
        if is_float == 1 { return token_new(TOK_FLOAT, num, line, col, 1) }
        return token_new(TOK_INT, num, line, col, 1)
    }
    
    // Identifiers and keywords
    if is_alpha(c) == 1 {
        let start = lexer_pos(l)
        while is_alnum(lexer_peek(l)) == 1 { lexer_advance(l) }
        let len = lexer_pos(l) - start
        let buf = __builtin_malloc(len + 1)
        let i = 0
        while i < len {
            __builtin_store8(buf + i, __builtin_load8(lexer_src(l) + start + i))
            i = i + 1
        }
        __builtin_store8(buf + len, 0)
        let tok_type = keyword_lookup(buf, len)
        let tok = token_new(tok_type, buf, line, col, len)
        token_set_str(tok, buf)
        return tok
    }
    
    // String literals
    if c == 34 {
        lexer_advance(l)
        let start = lexer_pos(l)
        while lexer_peek(l) != 34 && lexer_peek(l) != 0 {
            if lexer_peek(l) == 92 { lexer_advance(l) }
            lexer_advance(l)
        }
        let len = lexer_pos(l) - start
        let buf = __builtin_malloc(len + 1)
        let i = 0
        while i < len {
            __builtin_store8(buf + i, __builtin_load8(lexer_src(l) + start + i))
            i = i + 1
        }
        __builtin_store8(buf + len, 0)
        lexer_advance(l)
        let tok = token_new(TOK_STR, buf, line, col, len)
        token_set_str(tok, buf)
        return tok
    }
    
    // Character literals
    if c == 39 {
        lexer_advance(l)
        let ch = lexer_peek(l)
        if ch == 92 {
            lexer_advance(l)
            let esc = lexer_peek(l)
            if esc == 110 { ch = 10 }
            else if esc == 116 { ch = 9 }
            else if esc == 114 { ch = 13 }
            else if esc == 48 { ch = 0 }
            else if esc == 92 { ch = 92 }
            else if esc == 39 { ch = 39 }
            else { ch = esc }
        }
        lexer_advance(l)
        lexer_advance(l)
        return token_new(TOK_CHAR, ch, line, col, 1)
    }
    
    // Multi-character operators
    let c2 = lexer_peek_n(l, 1)
    let c3 = lexer_peek_n(l, 2)
    
    if c == 46 && c2 == 46 && c3 == 46 { lexer_advance(l) lexer_advance(l) lexer_advance(l) return token_new(TOK_DOTDOTDOT, 0, line, col, 3) }
    if c == 46 && c2 == 46 { lexer_advance(l) lexer_advance(l) return token_new(TOK_DOTDOT, 0, line, col, 2) }
    if c == 45 && c2 == 62 { lexer_advance(l) lexer_advance(l) return token_new(TOK_ARROW, 0, line, col, 2) }
    if c == 61 && c2 == 62 { lexer_advance(l) lexer_advance(l) return token_new(TOK_DARROW, 0, line, col, 2) }
    if c == 61 && c2 == 61 { lexer_advance(l) lexer_advance(l) return token_new(TOK_EQEQ, 0, line, col, 2) }
    if c == 33 && c2 == 61 { lexer_advance(l) lexer_advance(l) return token_new(TOK_NE, 0, line, col, 2) }
    if c == 60 && c2 == 61 { lexer_advance(l) lexer_advance(l) return token_new(TOK_LE, 0, line, col, 2) }
    if c == 62 && c2 == 61 { lexer_advance(l) lexer_advance(l) return token_new(TOK_GE, 0, line, col, 2) }
    if c == 38 && c2 == 38 { lexer_advance(l) lexer_advance(l) return token_new(TOK_AMPAMP, 0, line, col, 2) }
    if c == 124 && c2 == 124 { lexer_advance(l) lexer_advance(l) return token_new(TOK_PIPEPIPE, 0, line, col, 2) }
    if c == 43 && c2 == 61 { lexer_advance(l) lexer_advance(l) return token_new(TOK_PLUSEQ, 0, line, col, 2) }
    if c == 45 && c2 == 61 { lexer_advance(l) lexer_advance(l) return token_new(TOK_MINUSEQ, 0, line, col, 2) }
    if c == 42 && c2 == 61 { lexer_advance(l) lexer_advance(l) return token_new(TOK_STAREQ, 0, line, col, 2) }
    if c == 47 && c2 == 61 { lexer_advance(l) lexer_advance(l) return token_new(TOK_SLASHEQ, 0, line, col, 2) }
    
    // Single-character tokens
    lexer_advance(l)
    if c == 40 { return token_new(TOK_LPAREN, 0, line, col, 1) }
    if c == 41 { return token_new(TOK_RPAREN, 0, line, col, 1) }
    if c == 123 { return token_new(TOK_LBRACE, 0, line, col, 1) }
    if c == 125 { return token_new(TOK_RBRACE, 0, line, col, 1) }
    if c == 91 { return token_new(TOK_LBRACK, 0, line, col, 1) }
    if c == 93 { return token_new(TOK_RBRACK, 0, line, col, 1) }
    if c == 44 { return token_new(TOK_COMMA, 0, line, col, 1) }
    if c == 58 { return token_new(TOK_COLON, 0, line, col, 1) }
    if c == 59 { return token_new(TOK_SEMI, 0, line, col, 1) }
    if c == 46 { return token_new(TOK_DOT, 0, line, col, 1) }
    if c == 61 { return token_new(TOK_EQ, 0, line, col, 1) }
    if c == 60 { return token_new(TOK_LT, 0, line, col, 1) }
    if c == 62 { return token_new(TOK_GT, 0, line, col, 1) }
    if c == 43 { return token_new(TOK_PLUS, 0, line, col, 1) }
    if c == 45 { return token_new(TOK_MINUS, 0, line, col, 1) }
    if c == 42 { return token_new(TOK_STAR, 0, line, col, 1) }
    if c == 47 { return token_new(TOK_SLASH, 0, line, col, 1) }
    if c == 37 { return token_new(TOK_PERCENT, 0, line, col, 1) }
    if c == 38 { return token_new(TOK_AMP, 0, line, col, 1) }
    if c == 124 { return token_new(TOK_PIPE, 0, line, col, 1) }
    if c == 33 { return token_new(TOK_BANG, 0, line, col, 1) }
    if c == 94 { return token_new(TOK_CARET, 0, line, col, 1) }
    if c == 126 { return token_new(TOK_TILDE, 0, line, col, 1) }
    if c == 63 { return token_new(TOK_QUESTION, 0, line, col, 1) }
    if c == 64 { return token_new(TOK_AT, 0, line, col, 1) }
    
    token_new(TOK_EOF, 0, line, col, 0)
}

// ============================================================================
// TOKENIZE ENTIRE SOURCE
// ============================================================================

func tokenize(src: Int, len: Int) -> Int {
    print(76) print(48) print(10)  // L0 - entering tokenize
    let l = lexer_new(src, len)
    print(76) print(49) print(10)  // L1 - after lexer_new
    let tokens = vec_new()
    print(76) print(50) print(10)  // L2 - after vec_new
    let done = 0
    while done == 0 {
        print(76) print(51) print(10)  // L3 - in loop
        let tok = lexer_next(l)
        print(76) print(52) print(10)  // L4 - after lexer_next
        vec_push(tokens, tok)
        print(76) print(53) print(10)  // L5 - after vec_push
        if token_type(tok) == TOK_EOF { done = 1 }
    }
    print(76) print(54) print(10)  // L6 - done
    tokens
}
