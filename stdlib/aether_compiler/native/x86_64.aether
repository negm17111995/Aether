// AETHER NATIVE BACKEND - x86_64 INSTRUCTION ENCODER
// Generates raw x86_64 machine code

import std

// ============================================================================
// x86_64 REGISTERS
// ============================================================================

// 64-bit general purpose registers
const REG_RAX: Int = 0
const REG_RCX: Int = 1
const REG_RDX: Int = 2
const REG_RBX: Int = 3
const REG_RSP: Int = 4
const REG_RBP: Int = 5
const REG_RSI: Int = 6
const REG_RDI: Int = 7
const REG_R8: Int = 8
const REG_R9: Int = 9
const REG_R10: Int = 10
const REG_R11: Int = 11
const REG_R12: Int = 12
const REG_R13: Int = 13
const REG_R14: Int = 14
const REG_R15: Int = 15

// Register count
const REG_COUNT: Int = 16

// Calling convention: System V AMD64 ABI (Linux/macOS)
// Arguments: RDI, RSI, RDX, RCX, R8, R9
// Return: RAX
// Callee-saved: RBX, RBP, R12-R15
// Caller-saved: RAX, RCX, RDX, RSI, RDI, R8-R11

// ============================================================================
// CODE BUFFER
// ============================================================================

func x64_buffer_new() -> Int {
    let buf = ae_malloc(32)
    ae_store64(buf, ae_malloc(65536))  // code buffer
    ae_store64(buf + 8, 0)              // current position
    ae_store64(buf + 16, 65536)         // capacity
    ae_store64(buf + 24, vec_new())     // labels: (name, offset)
    buf
}

func x64_code(buf: Int) -> Int { ae_load64(buf) }
func x64_pos(buf: Int) -> Int { ae_load64(buf + 8) }
func x64_cap(buf: Int) -> Int { ae_load64(buf + 16) }
func x64_labels(buf: Int) -> Int { ae_load64(buf + 24) }
func x64_set_pos(buf: Int, p: Int) { ae_store64(buf + 8, p) }

func x64_emit(buf: Int, byte: Int) {
    let code = x64_code(buf)
    let pos = x64_pos(buf)
    ae_store8(code + pos, byte)
    x64_set_pos(buf, pos + 1)
}

func x64_emit16(buf: Int, val: Int) {
    x64_emit(buf, val % 256)
    x64_emit(buf, val / 256 % 256)
}

func x64_emit32(buf: Int, val: Int) {
    x64_emit(buf, val % 256)
    x64_emit(buf, val / 256 % 256)
    x64_emit(buf, val / 65536 % 256)
    x64_emit(buf, val / 16777216 % 256)
}

func x64_emit64(buf: Int, val: Int) {
    x64_emit32(buf, val)
    x64_emit32(buf, val / 4294967296)
}

// ============================================================================
// REX PREFIX ENCODING
// ============================================================================

// REX prefix: 0100WRXB
// W = 64-bit operand
// R = ModR/M reg extension
// X = SIB index extension
// B = ModR/M r/m or SIB base extension

func x64_rex(w: Int, r: Int, x: Int, b: Int) -> Int {
    64 + w * 8 + r * 4 + x * 2 + b
}

func x64_need_rex(reg: Int) -> Int {
    if reg >= 8 { return 1 }
    0
}

func x64_emit_rex(buf: Int, w: Int, reg: Int, rm: Int) {
    let r = 0
    let b = 0
    if reg >= 8 { r = 1 }
    if rm >= 8 { b = 1 }
    if w == 1 || r == 1 || b == 1 {
        x64_emit(buf, x64_rex(w, r, 0, b))
    }
}

func x64_emit_rex_w(buf: Int, reg: Int, rm: Int) {
    x64_emit_rex(buf, 1, reg, rm)
}

// ============================================================================
// MODR/M AND SIB ENCODING
// ============================================================================

// ModR/M byte: [mod:2][reg:3][r/m:3]
// mod = 00: [r/m], 01: [r/m]+disp8, 10: [r/m]+disp32, 11: register
func x64_modrm(mod: Int, reg: Int, rm: Int) -> Int {
    mod * 64 + (reg % 8) * 8 + rm % 8
}

// SIB byte: [scale:2][index:3][base:3]
func x64_sib(scale: Int, index: Int, base: Int) -> Int {
    scale * 64 + (index % 8) * 8 + base % 8
}

// ============================================================================
// BASIC INSTRUCTIONS
// ============================================================================

// MOV reg, reg (64-bit)
func x64_mov_rr(buf: Int, dst: Int, src: Int) {
    x64_emit_rex_w(buf, src, dst)
    x64_emit(buf, 137)  // 89 = MOV r/m64, r64
    x64_emit(buf, x64_modrm(3, src, dst))
}

// MOV reg, imm64
func x64_mov_ri64(buf: Int, reg: Int, imm: Int) {
    // REX.W + B8+rd
    let rex = x64_rex(1, 0, 0, 0)
    if reg >= 8 { x64_emit(buf, x64_rex(1, 0, 0, 1)) }
    else { x64_emit(buf, rex) }
    x64_emit(buf, 184 + reg % 8)  // B8+rd = MOV r64, imm64
    x64_emit64(buf, imm)
}

// MOV reg, imm32 (sign-extended)
func x64_mov_ri32(buf: Int, reg: Int, imm: Int) {
    x64_emit_rex_w(buf, 0, reg)
    x64_emit(buf, 199)  // C7 = MOV r/m64, imm32
    x64_emit(buf, x64_modrm(3, 0, reg))
    x64_emit32(buf, imm)
}

// MOV reg, [reg] (load from memory)
func x64_mov_rm(buf: Int, dst: Int, src_mem: Int) {
    x64_emit_rex_w(buf, dst, src_mem)
    x64_emit(buf, 139)  // 8B = MOV r64, r/m64
    if src_mem == REG_RSP || src_mem == REG_R12 {
        // Need SIB byte
        x64_emit(buf, x64_modrm(0, dst, 4))
        x64_emit(buf, x64_sib(0, 4, src_mem))
    } else {
        if src_mem == REG_RBP || src_mem == REG_R13 {
            // Need disp8 = 0
            x64_emit(buf, x64_modrm(1, dst, src_mem))
            x64_emit(buf, 0)
        } else {
            x64_emit(buf, x64_modrm(0, dst, src_mem))
        }
    }
}

// MOV reg, [reg+disp32]
func x64_mov_rm_disp(buf: Int, dst: Int, base: Int, disp: Int) {
    x64_emit_rex_w(buf, dst, base)
    x64_emit(buf, 139)
    if base == REG_RSP || base == REG_R12 {
        x64_emit(buf, x64_modrm(2, dst, 4))
        x64_emit(buf, x64_sib(0, 4, base))
    } else {
        x64_emit(buf, x64_modrm(2, dst, base))
    }
    x64_emit32(buf, disp)
}

// MOV [reg], reg (store to memory)
func x64_mov_mr(buf: Int, dst_mem: Int, src: Int) {
    x64_emit_rex_w(buf, src, dst_mem)
    x64_emit(buf, 137)  // 89 = MOV r/m64, r64
    if dst_mem == REG_RSP || dst_mem == REG_R12 {
        x64_emit(buf, x64_modrm(0, src, 4))
        x64_emit(buf, x64_sib(0, 4, dst_mem))
    } else {
        if dst_mem == REG_RBP || dst_mem == REG_R13 {
            x64_emit(buf, x64_modrm(1, src, dst_mem))
            x64_emit(buf, 0)
        } else {
            x64_emit(buf, x64_modrm(0, src, dst_mem))
        }
    }
}

// MOV [reg+disp32], reg
func x64_mov_mr_disp(buf: Int, base: Int, disp: Int, src: Int) {
    x64_emit_rex_w(buf, src, base)
    x64_emit(buf, 137)
    if base == REG_RSP || base == REG_R12 {
        x64_emit(buf, x64_modrm(2, src, 4))
        x64_emit(buf, x64_sib(0, 4, base))
    } else {
        x64_emit(buf, x64_modrm(2, src, base))
    }
    x64_emit32(buf, disp)
}

// ============================================================================
// ARITHMETIC INSTRUCTIONS
// ============================================================================

// ADD reg, reg
func x64_add_rr(buf: Int, dst: Int, src: Int) {
    x64_emit_rex_w(buf, src, dst)
    x64_emit(buf, 1)  // 01 = ADD r/m64, r64
    x64_emit(buf, x64_modrm(3, src, dst))
}

// ADD reg, imm32
func x64_add_ri(buf: Int, dst: Int, imm: Int) {
    x64_emit_rex_w(buf, 0, dst)
    if imm >= 0 - 128 && imm < 128 {
        x64_emit(buf, 131)  // 83 = ADD r/m64, imm8
        x64_emit(buf, x64_modrm(3, 0, dst))
        x64_emit(buf, imm % 256)
    } else {
        x64_emit(buf, 129)  // 81 = ADD r/m64, imm32
        x64_emit(buf, x64_modrm(3, 0, dst))
        x64_emit32(buf, imm)
    }
}

// SUB reg, reg
func x64_sub_rr(buf: Int, dst: Int, src: Int) {
    x64_emit_rex_w(buf, src, dst)
    x64_emit(buf, 41)  // 29 = SUB r/m64, r64
    x64_emit(buf, x64_modrm(3, src, dst))
}

// SUB reg, imm32
func x64_sub_ri(buf: Int, dst: Int, imm: Int) {
    x64_emit_rex_w(buf, 0, dst)
    if imm >= 0 - 128 && imm < 128 {
        x64_emit(buf, 131)  // 83
        x64_emit(buf, x64_modrm(3, 5, dst))  // /5 = SUB
        x64_emit(buf, imm % 256)
    } else {
        x64_emit(buf, 129)  // 81
        x64_emit(buf, x64_modrm(3, 5, dst))
        x64_emit32(buf, imm)
    }
}

// IMUL reg, reg (signed multiply)
func x64_imul_rr(buf: Int, dst: Int, src: Int) {
    x64_emit_rex_w(buf, dst, src)
    x64_emit(buf, 15)   // 0F
    x64_emit(buf, 175)  // AF = IMUL r64, r/m64
    x64_emit(buf, x64_modrm(3, dst, src))
}

// IMUL reg, reg, imm32
func x64_imul_rri(buf: Int, dst: Int, src: Int, imm: Int) {
    x64_emit_rex_w(buf, dst, src)
    if imm >= 0 - 128 && imm < 128 {
        x64_emit(buf, 107)  // 6B = IMUL r64, r/m64, imm8
        x64_emit(buf, x64_modrm(3, dst, src))
        x64_emit(buf, imm % 256)
    } else {
        x64_emit(buf, 105)  // 69 = IMUL r64, r/m64, imm32
        x64_emit(buf, x64_modrm(3, dst, src))
        x64_emit32(buf, imm)
    }
}

// IDIV r/m64 (signed divide: RDX:RAX / r/m64 -> RAX, RDX)
func x64_idiv_r(buf: Int, divisor: Int) {
    x64_emit_rex_w(buf, 0, divisor)
    x64_emit(buf, 247)  // F7
    x64_emit(buf, x64_modrm(3, 7, divisor))  // /7 = IDIV
}

// CQO (sign-extend RAX to RDX:RAX)
func x64_cqo(buf: Int) {
    x64_emit(buf, 72)   // REX.W
    x64_emit(buf, 153)  // 99 = CQO
}

// NEG reg
func x64_neg_r(buf: Int, reg: Int) {
    x64_emit_rex_w(buf, 0, reg)
    x64_emit(buf, 247)  // F7
    x64_emit(buf, x64_modrm(3, 3, reg))  // /3 = NEG
}

// NOT reg
func x64_not_r(buf: Int, reg: Int) {
    x64_emit_rex_w(buf, 0, reg)
    x64_emit(buf, 247)  // F7
    x64_emit(buf, x64_modrm(3, 2, reg))  // /2 = NOT
}

// AND reg, reg
func x64_and_rr(buf: Int, dst: Int, src: Int) {
    x64_emit_rex_w(buf, src, dst)
    x64_emit(buf, 33)  // 21 = AND r/m64, r64
    x64_emit(buf, x64_modrm(3, src, dst))
}

// OR reg, reg
func x64_or_rr(buf: Int, dst: Int, src: Int) {
    x64_emit_rex_w(buf, src, dst)
    x64_emit(buf, 9)  // 09 = OR r/m64, r64
    x64_emit(buf, x64_modrm(3, src, dst))
}

// XOR reg, reg
func x64_xor_rr(buf: Int, dst: Int, src: Int) {
    x64_emit_rex_w(buf, src, dst)
    x64_emit(buf, 49)  // 31 = XOR r/m64, r64
    x64_emit(buf, x64_modrm(3, src, dst))
}

// SHL reg, imm8
func x64_shl_ri(buf: Int, reg: Int, imm: Int) {
    x64_emit_rex_w(buf, 0, reg)
    x64_emit(buf, 193)  // C1
    x64_emit(buf, x64_modrm(3, 4, reg))  // /4 = SHL
    x64_emit(buf, imm % 256)
}

// SHR reg, imm8
func x64_shr_ri(buf: Int, reg: Int, imm: Int) {
    x64_emit_rex_w(buf, 0, reg)
    x64_emit(buf, 193)  // C1
    x64_emit(buf, x64_modrm(3, 5, reg))  // /5 = SHR
    x64_emit(buf, imm % 256)
}

// SAR reg, imm8 (arithmetic shift right)
func x64_sar_ri(buf: Int, reg: Int, imm: Int) {
    x64_emit_rex_w(buf, 0, reg)
    x64_emit(buf, 193)  // C1
    x64_emit(buf, x64_modrm(3, 7, reg))  // /7 = SAR
    x64_emit(buf, imm % 256)
}

// ============================================================================
// COMPARISON INSTRUCTIONS
// ============================================================================

// CMP reg, reg
func x64_cmp_rr(buf: Int, dst: Int, src: Int) {
    x64_emit_rex_w(buf, src, dst)
    x64_emit(buf, 57)  // 39 = CMP r/m64, r64
    x64_emit(buf, x64_modrm(3, src, dst))
}

// CMP reg, imm32
func x64_cmp_ri(buf: Int, reg: Int, imm: Int) {
    x64_emit_rex_w(buf, 0, reg)
    if imm >= 0 - 128 && imm < 128 {
        x64_emit(buf, 131)  // 83
        x64_emit(buf, x64_modrm(3, 7, reg))  // /7 = CMP
        x64_emit(buf, imm % 256)
    } else {
        x64_emit(buf, 129)  // 81
        x64_emit(buf, x64_modrm(3, 7, reg))
        x64_emit32(buf, imm)
    }
}

// TEST reg, reg
func x64_test_rr(buf: Int, dst: Int, src: Int) {
    x64_emit_rex_w(buf, src, dst)
    x64_emit(buf, 133)  // 85 = TEST r/m64, r64
    x64_emit(buf, x64_modrm(3, src, dst))
}

// ============================================================================
// CONTROL FLOW INSTRUCTIONS
// ============================================================================

// JMP rel32
func x64_jmp_rel32(buf: Int, offset: Int) {
    x64_emit(buf, 233)  // E9 = JMP rel32
    x64_emit32(buf, offset)
}

// JMP rel8
func x64_jmp_rel8(buf: Int, offset: Int) {
    x64_emit(buf, 235)  // EB = JMP rel8
    x64_emit(buf, offset % 256)
}

// JE/JZ rel32
func x64_je_rel32(buf: Int, offset: Int) {
    x64_emit(buf, 15)   // 0F
    x64_emit(buf, 132)  // 84 = JE rel32
    x64_emit32(buf, offset)
}

// JNE/JNZ rel32
func x64_jne_rel32(buf: Int, offset: Int) {
    x64_emit(buf, 15)
    x64_emit(buf, 133)  // 85 = JNE rel32
    x64_emit32(buf, offset)
}

// JL rel32 (signed less than)
func x64_jl_rel32(buf: Int, offset: Int) {
    x64_emit(buf, 15)
    x64_emit(buf, 140)  // 8C = JL rel32
    x64_emit32(buf, offset)
}

// JLE rel32 (signed less or equal)
func x64_jle_rel32(buf: Int, offset: Int) {
    x64_emit(buf, 15)
    x64_emit(buf, 142)  // 8E = JLE rel32
    x64_emit32(buf, offset)
}

// JG rel32 (signed greater than)
func x64_jg_rel32(buf: Int, offset: Int) {
    x64_emit(buf, 15)
    x64_emit(buf, 143)  // 8F = JG rel32
    x64_emit32(buf, offset)
}

// JGE rel32 (signed greater or equal)
func x64_jge_rel32(buf: Int, offset: Int) {
    x64_emit(buf, 15)
    x64_emit(buf, 141)  // 8D = JGE rel32
    x64_emit32(buf, offset)
}

// JB rel32 (unsigned below)
func x64_jb_rel32(buf: Int, offset: Int) {
    x64_emit(buf, 15)
    x64_emit(buf, 130)  // 82 = JB rel32
    x64_emit32(buf, offset)
}

// JAE rel32 (unsigned above or equal)
func x64_jae_rel32(buf: Int, offset: Int) {
    x64_emit(buf, 15)
    x64_emit(buf, 131)  // 83 = JAE rel32
    x64_emit32(buf, offset)
}

// CALL rel32
func x64_call_rel32(buf: Int, offset: Int) {
    x64_emit(buf, 232)  // E8 = CALL rel32
    x64_emit32(buf, offset)
}

// CALL reg (indirect call)
func x64_call_r(buf: Int, reg: Int) {
    if reg >= 8 { x64_emit(buf, x64_rex(0, 0, 0, 1)) }
    x64_emit(buf, 255)  // FF
    x64_emit(buf, x64_modrm(3, 2, reg))  // /2 = CALL r/m64
}

// RET
func x64_ret(buf: Int) {
    x64_emit(buf, 195)  // C3 = RET
}

// ============================================================================
// STACK INSTRUCTIONS
// ============================================================================

// PUSH reg
func x64_push_r(buf: Int, reg: Int) {
    if reg >= 8 { x64_emit(buf, x64_rex(0, 0, 0, 1)) }
    x64_emit(buf, 80 + reg % 8)  // 50+rd = PUSH r64
}

// POP reg
func x64_pop_r(buf: Int, reg: Int) {
    if reg >= 8 { x64_emit(buf, x64_rex(0, 0, 0, 1)) }
    x64_emit(buf, 88 + reg % 8)  // 58+rd = POP r64
}

// ============================================================================
// CONDITIONAL SET INSTRUCTIONS
// ============================================================================

// SETE reg8 (set if equal)
func x64_sete_r(buf: Int, reg: Int) {
    x64_emit_rex(buf, 0, 0, reg)
    x64_emit(buf, 15)
    x64_emit(buf, 148)  // 94 = SETE r/m8
    x64_emit(buf, x64_modrm(3, 0, reg))
}

// SETNE reg8
func x64_setne_r(buf: Int, reg: Int) {
    x64_emit_rex(buf, 0, 0, reg)
    x64_emit(buf, 15)
    x64_emit(buf, 149)  // 95 = SETNE r/m8
    x64_emit(buf, x64_modrm(3, 0, reg))
}

// SETL reg8
func x64_setl_r(buf: Int, reg: Int) {
    x64_emit_rex(buf, 0, 0, reg)
    x64_emit(buf, 15)
    x64_emit(buf, 156)  // 9C = SETL r/m8
    x64_emit(buf, x64_modrm(3, 0, reg))
}

// SETLE reg8
func x64_setle_r(buf: Int, reg: Int) {
    x64_emit_rex(buf, 0, 0, reg)
    x64_emit(buf, 15)
    x64_emit(buf, 158)  // 9E = SETLE r/m8
    x64_emit(buf, x64_modrm(3, 0, reg))
}

// SETG reg8
func x64_setg_r(buf: Int, reg: Int) {
    x64_emit_rex(buf, 0, 0, reg)
    x64_emit(buf, 15)
    x64_emit(buf, 159)  // 9F = SETG r/m8
    x64_emit(buf, x64_modrm(3, 0, reg))
}

// SETGE reg8
func x64_setge_r(buf: Int, reg: Int) {
    x64_emit_rex(buf, 0, 0, reg)
    x64_emit(buf, 15)
    x64_emit(buf, 157)  // 9D = SETGE r/m8
    x64_emit(buf, x64_modrm(3, 0, reg))
}

// MOVZX reg64, reg8 (zero extend)
func x64_movzx_r8(buf: Int, dst: Int, src: Int) {
    x64_emit_rex_w(buf, dst, src)
    x64_emit(buf, 15)
    x64_emit(buf, 182)  // B6 = MOVZX r64, r/m8
    x64_emit(buf, x64_modrm(3, dst, src))
}

// ============================================================================
// SYSTEM CALL (Linux)
// ============================================================================

// SYSCALL
func x64_syscall(buf: Int) {
    x64_emit(buf, 15)   // 0F
    x64_emit(buf, 5)    // 05 = SYSCALL
}

// ============================================================================
// LEA INSTRUCTION
// ============================================================================

// LEA reg, [reg+disp32]
func x64_lea_rd(buf: Int, dst: Int, base: Int, disp: Int) {
    x64_emit_rex_w(buf, dst, base)
    x64_emit(buf, 141)  // 8D = LEA r64, m
    if base == REG_RSP || base == REG_R12 {
        x64_emit(buf, x64_modrm(2, dst, 4))
        x64_emit(buf, x64_sib(0, 4, base))
    } else {
        x64_emit(buf, x64_modrm(2, dst, base))
    }
    x64_emit32(buf, disp)
}

// LEA reg, [rip+disp32] (RIP-relative)
func x64_lea_rip(buf: Int, dst: Int, disp: Int) {
    x64_emit_rex_w(buf, dst, 0)
    x64_emit(buf, 141)  // 8D = LEA
    x64_emit(buf, x64_modrm(0, dst, 5))  // mod=00, r/m=5 = RIP+disp32
    x64_emit32(buf, disp)
}

// ============================================================================
// NOP INSTRUCTION
// ============================================================================

func x64_nop(buf: Int) {
    x64_emit(buf, 144)  // 90 = NOP
}

// Multi-byte NOP for alignment
func x64_nop_n(buf: Int, n: Int) {
    let i = 0
    while i < n { x64_nop(buf) i = i + 1 }
}

// ============================================================================
// LABEL MANAGEMENT
// ============================================================================

func x64_label(buf: Int, name: Int) {
    let labels = x64_labels(buf)
    let label = ae_malloc(16)
    ae_store64(label, name)
    ae_store64(label + 8, x64_pos(buf))
    vec_push(labels, label)
}

func x64_find_label(buf: Int, name: Int) -> Int {
    let labels = x64_labels(buf)
    let i = 0
    while i < vec_len(labels) {
        let l = vec_get(labels, i)
        if ae_load64(l) == name { return ae_load64(l + 8) }
        i = i + 1
    }
    0 - 1
}

// ============================================================================
// FUNCTION PROLOGUE/EPILOGUE
// ============================================================================

func x64_prologue(buf: Int, stack_size: Int) {
    x64_push_r(buf, REG_RBP)
    x64_mov_rr(buf, REG_RBP, REG_RSP)
    if stack_size > 0 {
        x64_sub_ri(buf, REG_RSP, stack_size)
    }
}

func x64_epilogue(buf: Int) {
    x64_mov_rr(buf, REG_RSP, REG_RBP)
    x64_pop_r(buf, REG_RBP)
    x64_ret(buf)
}

// ============================================================================
// HELPER: GET CODE BYTES
// ============================================================================

func x64_get_code(buf: Int) -> Int {
    x64_code(buf)
}

func x64_get_size(buf: Int) -> Int {
    x64_pos(buf)
}
