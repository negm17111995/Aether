// AETHER COMPILER LEXER - Bootstrap Compatible
// (Separate from stdlib self-hosted compiler)

import std

// Token types
const L_TOK_EOF: Int = 0
const L_TOK_ID: Int = 1
const L_TOK_INT: Int = 2
const L_TOK_STR: Int = 3
const L_TOK_OP: Int = 4
const L_TOK_PUNCT: Int = 5

// Token: [type, value, line]
func lexer_token_new(typ: Int, val: Int, line: Int) -> Int {
    let t = ae_malloc(24)
    ae_store64(t, typ)
    ae_store64(t + 8, val)
    ae_store64(t + 16, line)
    t
}

func lexer_token_type(t: Int) -> Int { ae_load64(t) }
func lexer_token_value(t: Int) -> Int { ae_load64(t + 8) }
func lexer_token_line(t: Int) -> Int { ae_load64(t + 16) }

// Lexer state
func create_lexer(src: Int, len: Int) -> Int {
    let l = ae_malloc(32)
    ae_store64(l, src)
    ae_store64(l + 8, len)
    ae_store64(l + 16, 0)  // pos
    ae_store64(l + 24, 1)  // line
    l
}

func lexer_peek_char(l: Int) -> Int {
    let pos = ae_load64(l + 16)
    let len = ae_load64(l + 8)
    if pos >= len { return 0 }
    let src = ae_load64(l)
    ae_load8(src + pos)
}

func lexer_advance_char(l: Int) {
    let pos = ae_load64(l + 16)
    ae_store64(l + 16, pos + 1)
}

func lexer_get_token(l: Int) -> Int {
    let c = lexer_peek_char(l)
    if c == 0 {
        return lexer_token_new(L_TOK_EOF, 0, ae_load64(l + 24))
    }
    lexer_advance_char(l)
    lexer_token_new(L_TOK_PUNCT, c, ae_load64(l + 24))
}
